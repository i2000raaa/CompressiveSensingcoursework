{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd206d6f",
   "metadata": {},
   "source": [
    "#### Using UMich RSS data\n",
    "https://ieee-dataport.org/open-access/crawdad-umichrss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7495f523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from numpy import linalg\n",
    "from scipy import sparse\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from math import sqrt, log\n",
    "import statistics\n",
    "import scipy.linalg\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63767059-0485-4e53-97e5-d8b3c8bfe0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "n_available_cores = len(os.sched_getaffinity(0))\n",
    "print(n_available_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0250e1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open(\"Z.txt\") as f:\n",
    "    for line in f:\n",
    "        data.append([str(x) for x in line.split(sep='/n')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "202ff425",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in range(len(data)):\n",
    "    a.append(list([float(x) for x in data[i][0].split(sep=',')]))\n",
    "d = np.matrix(np.array(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02673e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-2.99179999, -3.20380913, -3.34146341, ...,  4.53658537,\n",
       "          4.3902439 ,  4.24390244],\n",
       "        [ 4.84401712,  4.84513899,  4.82926829, ...,  6.09756098,\n",
       "          5.92682927,  5.75609756],\n",
       "        [ 0.50567707,  0.65051792,  0.7804878 , ..., -0.19512195,\n",
       "         -0.02439024,  0.14634146],\n",
       "        ...,\n",
       "        [ 0.88614933,  0.80274108,  0.71293637, ...,  1.24084783,\n",
       "          1.29268293,  1.25746341],\n",
       "        [-4.50948509, -4.15286247, -3.81707317, ..., -5.90200444,\n",
       "         -6.48780488, -6.35803876],\n",
       "        [ 1.35049684,  1.20920845,  1.06097561, ...,  4.76216012,\n",
       "          4.80487805,  4.63326829]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be0f9479",
   "metadata": {},
   "source": [
    "Применим разложение по сингулярным значениям (SVD), чтобы проверить, имеет ли центрированная матрица хорошую аппроксимацию низкого ранга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83389d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_arr = np.array(d)\n",
    "u, s, vt = np.linalg.svd(main_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5256f190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.4 % singular values to capture 90 % variance\n"
     ]
    }
   ],
   "source": [
    "s2=[]\n",
    "s2sum=0\n",
    "for i in range(0, s.shape[0]):\n",
    "    s2.append(s[i]**2)\n",
    "    s2sum=s2sum+s[i]**2\n",
    "    \n",
    "s2matr=np.array(s2)    \n",
    "\n",
    "total_variance = 0\n",
    "num_sv = 0\n",
    "for i in range(0, s.shape[0]):\n",
    "    if total_variance < 0.9:\n",
    "        total_variance += s2matr[i]/s2sum\n",
    "        num_sv += 1\n",
    "print(round(num_sv/s.shape[0], 3)*100, \"% singular values to capture\", round(total_variance*100),\"% variance\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9db69e7d",
   "metadata": {},
   "source": [
    "Введём аномалии, чтобы увидеть, как это влияет на результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d11515f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomoly_size 14.753346168551886\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame(d)\n",
    "#используем экспоненциально-взвешенную скользящую среднюю (EWMA) для прогнозирования будущих записей на основе их прошлых значений\n",
    "df_ewm = df.ewm(alpha=0.8, adjust=False).mean()\n",
    "#используем максимальную разницу между фактическим и прогнозируемым значением в качестве размера вводимой аномалии\n",
    "dt = df - df_ewm\n",
    "max_by_columns = dt.max()\n",
    "anomoly_size = max(max_by_columns)\n",
    "print(\"Anomoly_size\", anomoly_size)\n",
    "\n",
    "#изменим долю записей для введения аномалий с 5% до 10%, а также масштабируем размер аномалии на s, который равен 0,5 или 1.\n",
    "s_5 = anomoly_size*0.5\n",
    "s_1 = anomoly_size*1\n",
    "\n",
    "random_indx_y10 = np.random.randint(0, 181, size=round(182*3127*0.1))\n",
    "random_indx_x10 = np.random.randint(0, 3126, size=round(182*3127*0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26ab19aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With s = 0.5, fraction = 10%  64.3 % singular values to capture 90 % variance\n"
     ]
    }
   ],
   "source": [
    "df_ = df.copy(deep=True)\n",
    "for i in range(len(random_indx_y10)):\n",
    "    y = int(random_indx_y10[i])\n",
    "    x = int(random_indx_x10[i])\n",
    "    df_.iat[y, x] =  df_.at[y, x] + s_5\n",
    "\n",
    "df_matrix = np.asmatrix(df_)\n",
    "u, s, vt = np.linalg.svd(df_matrix)\n",
    "\n",
    "s2=[]\n",
    "s2sum=0\n",
    "for i in range(0, s.shape[0]):\n",
    "    s2.append(s[i]**2)\n",
    "    s2sum=s2sum+s[i]**2\n",
    "    \n",
    "s2matr=np.array(s2)    \n",
    "total_variance = 0\n",
    "num_sv = 0\n",
    "for i in range(0, s.shape[0]):\n",
    "    if total_variance < 0.9:\n",
    "        total_variance += s2matr[i]/s2sum\n",
    "        num_sv += 1\n",
    "\n",
    "print(\"With s = 0.5, fraction = 10% \", round(num_sv/s.shape[0], 3)*100, \"% singular values to capture\", round(total_variance*100),\"% variance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f75f715c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With s = 0.5, fraction = 5%  53.300000000000004 % singular values to capture 90 % variance\n"
     ]
    }
   ],
   "source": [
    "df_ = df.copy(deep=True)\n",
    "for i in range(len(random_indx_y10)//2):\n",
    "    y = int(random_indx_y10[i])\n",
    "    x = int(random_indx_x10[i])\n",
    "    df_.iat[y, x] =  df_.at[y, x] + s_5\n",
    "\n",
    "df_matrix = np.asmatrix(df_)\n",
    "u, s, vt = np.linalg.svd(df_matrix)\n",
    "\n",
    "s2=[]\n",
    "s2sum=0\n",
    "for i in range(0, s.shape[0]):\n",
    "    s2.append(s[i]**2)\n",
    "    s2sum=s2sum+s[i]**2\n",
    "    \n",
    "s2matr=np.array(s2)    \n",
    "total_variance = 0\n",
    "num_sv = 0\n",
    "for i in range(0, s.shape[0]):\n",
    "    if total_variance < 0.9:\n",
    "        total_variance += s2matr[i]/s2sum\n",
    "        num_sv += 1\n",
    "\n",
    "print(\"With s = 0.5, fraction = 5% \", round(num_sv/s.shape[0], 3)*100, \"% singular values to capture\", round(total_variance*100),\"% variance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ad07a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With s = 1, fraction = 10%  78.60000000000001 % singular values to capture 90 % variance\n"
     ]
    }
   ],
   "source": [
    "df_ = df.copy(deep=True)\n",
    "for i in range(len(random_indx_y10)):\n",
    "    y = int(random_indx_y10[i])\n",
    "    x = int(random_indx_x10[i])\n",
    "    df_.iat[y, x] =  df_.at[y, x] + s_1\n",
    "\n",
    "df_matrix = np.asmatrix(df_)\n",
    "u, s, vt = np.linalg.svd(df_matrix)\n",
    "\n",
    "s2=[]\n",
    "s2sum=0\n",
    "for i in range(0, s.shape[0]):\n",
    "    s2.append(s[i]**2)\n",
    "    s2sum=s2sum+s[i]**2\n",
    "    \n",
    "s2matr=np.array(s2)    \n",
    "total_variance = 0\n",
    "num_sv = 0\n",
    "for i in range(0, s.shape[0]):\n",
    "    if total_variance < 0.9:\n",
    "        total_variance += s2matr[i]/s2sum\n",
    "        num_sv += 1\n",
    "print(\"With s = 1, fraction = 10% \", round(num_sv/s.shape[0], 3)*100, \"% singular values to capture\", round(total_variance*100),\"% variance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d20eaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With s = 1, fraction = 5%  73.6 % singular values to capture 90 % variance\n"
     ]
    }
   ],
   "source": [
    "df_ = df.copy(deep=True)\n",
    "for i in range(len(random_indx_y10)//2):\n",
    "    y = int(random_indx_y10[i])\n",
    "    x = int(random_indx_x10[i])\n",
    "    df_.iat[y, x] =  df_.at[y, x] + s_1\n",
    "\n",
    "df_matrix = np.asmatrix(df_)\n",
    "u, s, vt = np.linalg.svd(df_matrix)\n",
    "\n",
    "s2=[]\n",
    "s2sum=0\n",
    "for i in range(0, s.shape[0]):\n",
    "    s2.append(s[i]**2)\n",
    "    s2sum=s2sum+s[i]**2\n",
    "    \n",
    "s2matr=np.array(s2)    \n",
    "total_variance = 0\n",
    "num_sv = 0\n",
    "for i in range(0, s.shape[0]):\n",
    "    if total_variance < 0.9:\n",
    "        total_variance += s2matr[i]/s2sum\n",
    "        num_sv += 1\n",
    "\n",
    "print(\"With s = 1, fraction = 5% \", round(num_sv/s.shape[0], 3)*100, \"% singular values to capture\", round(total_variance*100),\"% variance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "535b175d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#так как именно s = 1, fraction = 5% будет использовано в LENS разложении, выведем количество сингулярных значений объясняющих 90% информации \n",
    "num_sv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "035b4800",
   "metadata": {},
   "source": [
    "Чем вводится больше аномалий, или чем они больше по размеру, тем больший процент сингулярных чисел необходим для объяснения 90% вариативности данных."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84fbad0b",
   "metadata": {},
   "source": [
    "### LENS Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ec553e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_thresh(x, T):\n",
    "    \"\"\"Soft threshold function\"\"\"\n",
    "    return  np.multiply(np.sign(x), np.maximum(np.abs(x) - T, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dccdf70-f655-4bab-a1dc-3c4151476428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADMM(D, frac_anomaly, frac_missing, random_indx_y10_miss, random_indx_x10_miss, m=182, n=3127):\n",
    "\n",
    "    X = np.random.randint(-70, 61, size=(n, n)) \n",
    "    Y = np.random.randint(-70, 61, size=(m, n))\n",
    "    Z = np.random.randint(-70, 61, size=(m, n))   \n",
    "    A = np.array([np.where(x == None, 0, 1) for x in D])\n",
    "    B = np.eye(182)\n",
    "    C = np.eye(182)\n",
    "    X_0 = np.random.randint(-70, 61, size=(n, n))\n",
    "    X_1 = np.random.randint(-70, 61, size=(n, n))\n",
    "    Y_0 = np.random.randint(-70, 61, size=(m, n))\n",
    "    M_0 = np.random.randint(-1, 1, size=(n, n))\n",
    "    M_1 = np.random.randint(-1, 1, size=(n, n))\n",
    "    N = np.random.randint(-1, 1, size=(m, n))\n",
    "    M = np.random.randint(-1, 1, size=(m, n))\n",
    "    W = np.random.randint(-1, 1, size=(m, n))\n",
    "    \n",
    "    #списки индексов ячеек с  не пропущенными значениями\n",
    "    non_elem = np.argwhere(D != None)\n",
    "    D[np.isnan(D)] = 0\n",
    "    E = np.array([[1 for col in range(3127)] for row in range(182)])\n",
    "    for i in range(len(non_elem)):\n",
    "        E[non_elem[i][0]][non_elem[i][1]] = 0\n",
    "        W[non_elem[i][0]][non_elem[i][1]] = 0\n",
    "    shape_d = (m, n)    #(182, 3127)\n",
    "    shape_X = shape_Y = shape_d\n",
    "    size_d = m*n\n",
    "    #nu_D - это доля записей в D, которые не являются ни пропущенными, ни ошибочными.\n",
    "    nu_D = 1 - (frac_missing+frac_anomaly)/size_d\n",
    "\n",
    "    mu = 1.01\n",
    "    p = 1.05\n",
    "    \n",
    "    J = D - A@X_0 - B@Y_0 - W\n",
    "    alpha = (shape_X[0]**(0.5) + shape_X[1]**(0.5))*nu_D\n",
    "    beta = (2*math.log(shape_Y[0]*shape_Y[1]))**(0.5)\n",
    "    gamma = 1\n",
    "    theta = 10\n",
    "    K = 1\n",
    "    P_1 = np.eye(n)\n",
    "    q1_list_1 = [1] +  [0] * (n-1)\n",
    "    q1_list_2 = [1, -1] + [0] * (n-2)\n",
    "    Q_1 =  scipy.linalg.toeplitz(q1_list_1, q1_list_2)\n",
    "    R_1 = np.zeros(n)\n",
    "\n",
    "    #sigma_D определяется на каждой иттерации ADM алгоритма\n",
    "    #как стандартное отклонение ряда значений J[i,j], где E[i,j]=0\n",
    "    tmp_nonzero = []\n",
    "    indices = np.nonzero(~np.isnan(E))\n",
    "    non_elem = np.column_stack(indices)\n",
    "    for i in range(len(non_elem)):\n",
    "        tmp_nonzero.append(J[non_elem[i][0]][non_elem[i][1]]) \n",
    "    sigma_D = statistics.stdev(tmp_nonzero)\n",
    "    sigma = theta*sigma_D\n",
    "    MAX_ITER = 70\n",
    "    for i in range(MAX_ITER):\n",
    "        print(\"Iteration\", i)\n",
    "\n",
    "        #first step X\n",
    "        J = 1/(K+1)*(X_1 + M_1/mu + X_0 + M_0/mu)\n",
    "        t = alpha/(mu*(K+1))        \n",
    "        # QR факторизация\n",
    "        Q, R = np.linalg.qr(J)   \n",
    "        u, s, vt = np.linalg.svd(J, full_matrices=False)\n",
    "        S = np.diag(s)\n",
    "        s = soft_thresh(S, t)\n",
    "        s = np.diag(s)\n",
    "        X = Q.dot(u[:,:2]).dot(np.diag(s[:2])).dot(vt[:2,:])\n",
    "\n",
    "        #second step \n",
    "        J = X - M_1/mu\n",
    "        R = P_1.transpose() @ R_1 @ Q_1 + ((mu*sigma)/gamma) * J\n",
    "        up, sp, vtp = np.linalg.svd(P_1 @ P_1.transpose())\n",
    "        uq, sq, vtq = np.linalg.svd(Q_1 @ Q_1.transpose())\n",
    "        X_1 = up @ np.divide((vtp @ R @ uq), (sp*sq.transpose() + (mu*sigma/gamma))) @ vtq\n",
    "        \n",
    "        #third step with X0\n",
    "        J_0 = X-M_0/mu\n",
    "        J = D-np.matmul(B, Y_0)-np.matmul(C, Z)-W + M/mu\n",
    "        X_0 = np.linalg.inv(A.transpose()@A + np.eye(n))@(A.transpose()@J + J_0)\n",
    "        \n",
    "        #fourth step Y\n",
    "        J = Y_0 + N/mu\n",
    "        t = beta/mu\n",
    "        Y = soft_thresh(J, t)\n",
    "\n",
    "        #fifth step Y_0\n",
    "        J_0 = Y - N/mu\n",
    "        J = D-np.matmul(A, X_0)-np.matmul(C, Z)-W + M/mu\n",
    "        Y_0 = np.linalg.inv(B.transpose()@B + np.eye(m))@(B.transpose()@J + J_0)\n",
    "        \n",
    "        #sixth step Z\n",
    "        J = D-np.matmul(A, X_0)-np.matmul(B, Y_0)-W + M/mu\n",
    "        Z = np.linalg.inv(1/(mu*sigma)*np.eye(m) + np.matmul(C.transpose(), C))@(np.matmul(C.transpose(),J))\n",
    "        \n",
    "        #seventh step W\n",
    "        W = np.multiply(E, (D-np.matmul(A, X_0)-np.matmul(B, Y_0)-np.matmul(C, Z) + M/mu))\n",
    "        \n",
    "        #eighth step sigma\n",
    "        #sigma определяется на каждой иттерации ADM алгоритма, \n",
    "        #как стандартное отклонение ряда значений J[i,j], где E[i,j]=0\n",
    "        theta = 10\n",
    "        J = D-np.matmul(A, X_0)-np.matmul(B, Y_0)-W\n",
    "        tmp_nonzero = []\n",
    "        indices = np.nonzero(~np.isnan(E))\n",
    "        non_elem = np.column_stack(indices)\n",
    "        for i in range(len(non_elem)):\n",
    "            tmp_nonzero.append(J[non_elem[i][0]][non_elem[i][1]])      \n",
    "        \n",
    "        sigma_D = statistics.stdev(tmp_nonzero)           \n",
    "        sigma = theta*sigma_D\n",
    "\n",
    "        #ninth step\n",
    "        #Every itteration update M, M_0, N\n",
    "        M = M + mu * (D-np.matmul(A, X_0)-np.matmul(B, Y_0)-np.matmul(C, Z)-W)\n",
    "        M_0 = M_0 + mu * (X_0-X)\n",
    "        M_1 = M_1 + mu*(X_1-X)\n",
    "        N = N +  mu *  (Y_0-Y)\n",
    "        \n",
    "        #tenth step\n",
    "        #Every itteration update mu\n",
    "        mu = p*mu\n",
    "        #Every 100 iterations, we multiply ρ by 1.05\n",
    "        if isinstance(i//100, int):\n",
    "            p_ = 1.05\n",
    "            p = p*p_\n",
    "        if sigma_D == 0:\n",
    "            return D\n",
    "        D = A @ X_0 + B @ Y_0 + C @ Z + W\n",
    "    D = A @ X_0 + B @ Y_0 + C @ Z + W    \n",
    "    return D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8e0ef7b1-740e-4793-b84f-6d594a08941a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n",
      "Iteration 30\n",
      "Iteration 31\n",
      "Iteration 32\n",
      "Iteration 33\n",
      "Iteration 34\n",
      "Iteration 35\n",
      "Iteration 36\n",
      "Iteration 37\n",
      "Iteration 38\n",
      "Iteration 39\n",
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n",
      "Iteration 30\n",
      "Iteration 31\n",
      "Iteration 32\n",
      "Iteration 33\n",
      "Iteration 34\n",
      "Iteration 35\n",
      "Iteration 36\n",
      "Iteration 37\n",
      "Iteration 38\n",
      "Iteration 39\n",
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n",
      "Iteration 30\n",
      "Iteration 31\n",
      "Iteration 32\n",
      "Iteration 33\n",
      "Iteration 34\n",
      "Iteration 35\n",
      "Iteration 36\n",
      "Iteration 37\n",
      "Iteration 38\n",
      "Iteration 39\n",
      "[1.0685396201789548, 1.0688202254703911, 1.0701291284008667]\n",
      "[1.0883927288741377, 1.0911173416459856, 1.0972503144414398]\n",
      "[0.743980204085986, 0.7365128374516482, 0.7460075734562487]\n",
      "CPU times: user 4h 59min, sys: 6min 35s, total: 5h 5min 36s\n",
      "Wall time: 1h 37min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.impute import KNNImputer\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "df_ = df.copy(deep=True)\n",
    "D = np.asmatrix(df_)\n",
    "tmp_arr = copy.deepcopy(main_arr)\n",
    "frac_anomaly = round(100*150*0.1)//2\n",
    "frac_anomaly = 0\n",
    "new_loss_result_list = []\n",
    "new_loss_result_list_2 = []\n",
    "new_loss_result_list_3 = []\n",
    "\n",
    "loss_probability = [0.2, 0.4, 0.8]   #first technique\n",
    "for loss in loss_probability:\n",
    "    new_nmae_err_list = []\n",
    "    new_nmae_err_list_2 = []\n",
    "    new_nmae_err_list_3 = []\n",
    "    nmae_err_list = []\n",
    "    nmae_err_list_2 = []\n",
    "    nmae_err_list_3 = []\n",
    "    frac_missing = round(182*3127*loss)\n",
    "    for i in range(1):\n",
    "        #first technique\n",
    "        random_indx_y10_miss = np.random.randint(0, 182, size=round(182*3127*loss))\n",
    "        random_indx_x10_miss = np.random.randint(0, 3127, size=round(182*3127*loss))\n",
    "        \n",
    "#         #second technique\n",
    "#         random_indx_y10_miss = np.array([i for i in range(182)])\n",
    "#         random_indx_x10_miss = np.random.randint(0, 3127, size=round(182*3127*loss))\n",
    "        \n",
    "#         #third technique\n",
    "#         random_indx_y10_miss = np.random.randint(0, 182, size=round(182*3127*loss))\n",
    "#         random_indx_x10_miss = np.array([i for i in range(3127)])\n",
    "        \n",
    "#         #third technique\n",
    "#         random_indx_y10_miss = np.random.randint(0, 100, size=round(100*150*loss))\n",
    "#         random_indx_x10_miss = np.random.randint(0, 150, size=round(100*150*p))\n",
    "\n",
    "#         #fourth technique\n",
    "#         random_indx_y10_miss = np.array([i for i in range(100)])\n",
    "#         random_indx_x10_miss = np.random.randint(0, 150, size=round(100*150*loss))\n",
    "        \n",
    "#         #fifth technique\n",
    "#         random_indx_y10_miss = np.random.randint(0, 100, size=round(100*150*loss))\n",
    "#         random_indx_x10_miss = np.array([i for i in range(150)])\n",
    "\n",
    "        list_D = []\n",
    "        list_result_D = []\n",
    "        list_result_D_2 = []\n",
    "        list_result_D_3 = []\n",
    "        tmp_arr = copy.deepcopy(main_arr)\n",
    "        for i in range(len(random_indx_y10_miss)):\n",
    "            y = int(random_indx_y10_miss[i])\n",
    "            x = int(random_indx_x10_miss[i])\n",
    "            list_D.append(main_arr[y][x])\n",
    "            tmp_arr[y][x] = None\n",
    "        \n",
    "        mean = np.nanmean(tmp_arr)\n",
    "        tmp_arr_for_svd = copy.deepcopy(tmp_arr)\n",
    "        tmp_arr_for_svd[np.isnan(tmp_arr_for_svd)] = 0\n",
    "        \n",
    "        indices = np.nonzero(np.isnan(tmp_arr_for_svd)) \n",
    "        random_indx_y10_anomal = np.random.randint(0, 182, size=round(182*3127*0.1))\n",
    "        random_indx_x10_anomal = np.random.randint(0, 3127, size=round(182*3127*0.1))\n",
    "    \n",
    "        for i in range(len(random_indx_y10_anomal)//2):\n",
    "            y = int(random_indx_y10_anomal[i])\n",
    "            x = int(random_indx_x10_anomal[i])\n",
    "            tmp_arr[y][x] += s_1\n",
    "            tmp_arr_for_svd[y][x] += s_1\n",
    "        \n",
    "        U, sigma, V = np.linalg.svd(tmp_arr_for_svd)\n",
    "        # Выберем только первые две компоненты для аппроксимации\n",
    "        U = U[:, :2]\n",
    "        sigma = np.diag(sigma[:2])\n",
    "        V = V[:2, :]\n",
    "        # Вычислим аппроксимированную матрицу\n",
    "        D_approx = U @ sigma @ V\n",
    "\n",
    "        # Применяем K ближайших соседей для локальной интерполяции:\n",
    "        knn = KNeighborsRegressor(n_neighbors=2)\n",
    "        matrix_interp = knn.fit(D_approx, main_arr).predict(D_approx)\n",
    "\n",
    "        # Получаем итоговую матрицу, заменяя пропущенные значения после локальной интерполяции:\n",
    "        D_svd_knn = copy.deepcopy(tmp_arr)\n",
    "        D_svd_knn[np.isnan(D_svd_knn)] = matrix_interp[np.isnan(D_svd_knn)]\n",
    "        \n",
    "        for i in range(len(random_indx_y10_miss)):\n",
    "            y = int(random_indx_y10_miss[i])\n",
    "            x = int(random_indx_x10_miss[i])\n",
    "            list_result_D_3.append(D_svd_knn[y][x])\n",
    "            list_result_D_2.append(D_approx[y][x])\n",
    "           \n",
    "            \n",
    "        m=182\n",
    "        n=3127\n",
    "        result_D = ADMM(tmp_arr, frac_anomaly, frac_missing, random_indx_y10_miss, random_indx_x10_miss, m, n)\n",
    "        for i in range(len(random_indx_y10_miss)):\n",
    "            y = int(random_indx_y10_miss[i])\n",
    "            x = int(random_indx_x10_miss[i])\n",
    "            list_result_D.append(result_D[y][x])         \n",
    "        \n",
    "        raznost = [x - y for x, y in zip(list_D, list_result_D)]\n",
    "        raznost_2 = [x - y for x, y in zip(list_D, list_result_D_2)]\n",
    "        raznost_3 = [x - y for x, y in zip(list_D, list_result_D_3)]\n",
    "        new_nmae_err_list.append(np.mean(np.abs(raznost) / np.nanmean(np.abs(list_D))))\n",
    "        new_nmae_err_list_2.append(np.mean(np.abs(raznost_2) / np.nanmean(np.abs(list_D))))\n",
    "        new_nmae_err_list_3.append(np.mean(np.abs(raznost_3) / np.nanmean(np.abs(list_D))))\n",
    "    \n",
    "    new_loss_result_list.append(np.mean(new_nmae_err_list))\n",
    "    new_loss_result_list_2.append(np.mean(new_nmae_err_list_2))\n",
    "    new_loss_result_list_3.append(np.mean(new_nmae_err_list_3))   \n",
    "\n",
    "print(new_loss_result_list)\n",
    "print(new_loss_result_list_2)\n",
    "print(new_loss_result_list_3)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59ac04ca-cfc6-4433-9b81-5d254d16d554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n",
      "Iteration 30\n",
      "Iteration 31\n",
      "Iteration 32\n",
      "Iteration 33\n",
      "Iteration 34\n",
      "Iteration 35\n",
      "Iteration 36\n",
      "Iteration 37\n",
      "Iteration 38\n",
      "Iteration 39\n",
      "Iteration 40\n",
      "Iteration 41\n",
      "Iteration 42\n",
      "Iteration 43\n",
      "Iteration 44\n",
      "Iteration 45\n",
      "Iteration 46\n",
      "Iteration 47\n",
      "Iteration 48\n",
      "Iteration 49\n",
      "Iteration 50\n",
      "Iteration 51\n",
      "Iteration 52\n",
      "Iteration 53\n",
      "Iteration 54\n",
      "Iteration 55\n",
      "Iteration 56\n",
      "Iteration 57\n",
      "Iteration 58\n",
      "Iteration 59\n",
      "Iteration 60\n",
      "Iteration 61\n",
      "Iteration 62\n",
      "Iteration 63\n",
      "Iteration 64\n",
      "Iteration 65\n",
      "Iteration 66\n",
      "Iteration 67\n",
      "Iteration 68\n",
      "Iteration 69\n",
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n",
      "Iteration 30\n",
      "Iteration 31\n",
      "Iteration 32\n",
      "Iteration 33\n",
      "Iteration 34\n",
      "Iteration 35\n",
      "Iteration 36\n",
      "Iteration 37\n",
      "Iteration 38\n",
      "Iteration 39\n",
      "Iteration 40\n",
      "Iteration 41\n",
      "Iteration 42\n",
      "Iteration 43\n",
      "Iteration 44\n",
      "Iteration 45\n",
      "Iteration 46\n",
      "Iteration 47\n",
      "Iteration 48\n",
      "Iteration 49\n",
      "Iteration 50\n",
      "Iteration 51\n",
      "Iteration 52\n",
      "Iteration 53\n",
      "Iteration 54\n",
      "Iteration 55\n",
      "Iteration 56\n",
      "Iteration 57\n",
      "Iteration 58\n",
      "Iteration 59\n",
      "Iteration 60\n",
      "Iteration 61\n",
      "Iteration 62\n",
      "Iteration 63\n",
      "Iteration 64\n",
      "Iteration 65\n",
      "Iteration 66\n",
      "Iteration 67\n",
      "Iteration 68\n",
      "Iteration 69\n",
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n",
      "Iteration 30\n",
      "Iteration 31\n",
      "Iteration 32\n",
      "Iteration 33\n",
      "Iteration 34\n",
      "Iteration 35\n",
      "Iteration 36\n",
      "Iteration 37\n",
      "Iteration 38\n",
      "Iteration 39\n",
      "Iteration 40\n",
      "Iteration 41\n",
      "Iteration 42\n",
      "Iteration 43\n",
      "Iteration 44\n",
      "Iteration 45\n",
      "Iteration 46\n",
      "Iteration 47\n",
      "Iteration 48\n",
      "Iteration 49\n",
      "Iteration 50\n",
      "Iteration 51\n",
      "Iteration 52\n",
      "Iteration 53\n",
      "Iteration 54\n",
      "Iteration 55\n",
      "Iteration 56\n",
      "Iteration 57\n",
      "Iteration 58\n",
      "Iteration 59\n",
      "Iteration 60\n",
      "Iteration 61\n",
      "Iteration 62\n",
      "Iteration 63\n",
      "Iteration 64\n",
      "Iteration 65\n",
      "Iteration 66\n",
      "Iteration 67\n",
      "Iteration 68\n",
      "Iteration 69\n",
      "[1.0569441198695746, 1.0585403946893128, 1.0574084696455937]\n",
      "[1.0597882116399937, 1.0543928191988092, 1.0553808194150176]\n",
      "[0.6337956668487751, 0.701372279156839, 0.6397913084711652]\n",
      "CPU times: user 9h 21min 18s, sys: 17min, total: 9h 38min 19s\n",
      "Wall time: 2h 24min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.impute import KNNImputer\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "df_ = df.copy(deep=True)\n",
    "D = np.asmatrix(df_)\n",
    "tmp_arr = copy.deepcopy(main_arr)\n",
    "frac_anomaly = round(100*150*0.1)//2\n",
    "#frac_anomaly = 0\n",
    "new_loss_result_list = []\n",
    "new_loss_result_list_2 = []\n",
    "new_loss_result_list_3 = []\n",
    "\n",
    "p_ = [0.2, 0.4, 0.8]\n",
    "anomaly_size = [0.5, 1, 2, 5]\n",
    "anomaly_ratio = [0, 0.05, 0.1, 0.2]\n",
    "loss_probability = [0.2, 0.4, 0.8]   #first technique\n",
    "loss = 0.2\n",
    "anomaly_r = 0.1\n",
    "anomaly_s = 1\n",
    "frac_anomaly = anomaly_r\n",
    "\n",
    "for p in p_:\n",
    "#for anomaly_r in anomaly_ratio:\n",
    "#for anomaly_s in anomaly_size:\n",
    "#for loss in loss_probability:\n",
    "    new_nmae_err_list = []\n",
    "    new_nmae_err_list_2 = []\n",
    "    new_nmae_err_list_3 = []\n",
    "    nmae_err_list = []\n",
    "    nmae_err_list_2 = []\n",
    "    nmae_err_list_3 = []\n",
    "    frac_missing = round(100*150*loss)\n",
    "    #frac_anomaly = round(100*150*loss)\n",
    "    for i in range(1):\n",
    "#         #first technique\n",
    "        # random_indx_y10_miss = np.random.randint(0, 100, size=round(100*150*loss))\n",
    "        # random_indx_x10_miss = np.random.randint(0, 150, size=round(100*150*loss))\n",
    "        \n",
    "        #second technique\n",
    "        random_indx_y10_miss = np.random.randint(0, 100, size=round(100*150*0.5))\n",
    "        random_indx_x10_miss = np.random.randint(0, 150, size=round(100*150*p))\n",
    "        \n",
    "#         #third technique\n",
    "#         random_indx_y10_miss = np.random.randint(0, 100, size=round(100*150*p))\n",
    "#         random_indx_x10_miss = np.random.randint(0, 150, size=round(100*150*0.5))\n",
    "\n",
    "#         #fourth technique\n",
    "#         random_indx_y10_miss = np.array([i for i in range(100)])\n",
    "#         random_indx_x10_miss = np.random.randint(0, 150, size=round(100*150*loss))\n",
    "        \n",
    "#         #fifth technique\n",
    "#         random_indx_y10_miss = np.random.randint(0, 100, size=round(100*150*loss))\n",
    "#         random_indx_x10_miss = np.array([i for i in range(150)])\n",
    "      \n",
    "        list_D = []\n",
    "        list_result_D = []\n",
    "        list_result_D_2 = []\n",
    "        list_result_D_3 = []\n",
    "        tmp_arr = copy.deepcopy(main_arr)\n",
    "        for i in range(len(random_indx_y10_miss)):\n",
    "            y = int(random_indx_y10_miss[i])\n",
    "            for i in range(len(random_indx_x10_miss)):\n",
    "                x = int(random_indx_x10_miss[i])\n",
    "                list_D.append(main_arr[y][x])\n",
    "                tmp_arr[y][x] = None\n",
    "        \n",
    "        mean = np.nanmean(tmp_arr)\n",
    "        tmp_arr_for_svd = copy.deepcopy(tmp_arr)\n",
    "        tmp_arr_for_svd[np.isnan(tmp_arr_for_svd)] = 0\n",
    "        \n",
    "        indices = np.nonzero(np.isnan(tmp_arr_for_svd))  \n",
    "        random_indx_y10_anomal = np.random.randint(0, 100, size=round(100*150*anomaly_r))\n",
    "        random_indx_x10_anomal = np.random.randint(0, 150, size=round(100*150*anomaly_r))\n",
    "    \n",
    "        for i in range(len(random_indx_y10_anomal)):\n",
    "            y = int(random_indx_y10_anomal[i])\n",
    "            x = int(random_indx_x10_anomal[i])\n",
    "            tmp_arr[y][x] += s_1*anomaly_s\n",
    "            tmp_arr_for_svd[y][x] += s_1*anomaly_s\n",
    "        \n",
    "        U, sigma, V = np.linalg.svd(tmp_arr_for_svd)\n",
    "        # Выберем только первые две компоненты для аппроксимации\n",
    "        U = U[:, :2]\n",
    "        sigma = np.diag(sigma[:2])\n",
    "        V = V[:2, :]\n",
    "        # Вычислим аппроксимированную матрицу\n",
    "        D_approx = U @ sigma @ V\n",
    "\n",
    "        # Применяем K ближайших соседей для локальной интерполяции:\n",
    "        knn = KNeighborsRegressor(n_neighbors=2)\n",
    "        matrix_interp = knn.fit(D_approx, main_arr).predict(D_approx)\n",
    "\n",
    "        # Получаем итоговую матрицу, заменяя пропущенные значения после локальной интерполяции:\n",
    "        D_svd_knn = copy.deepcopy(tmp_arr)\n",
    "        D_svd_knn[np.isnan(D_svd_knn)] = matrix_interp[np.isnan(D_svd_knn)]\n",
    "        for i in range(len(random_indx_y10_miss)):\n",
    "            y = int(random_indx_y10_miss[i])\n",
    "            for i in range(len(random_indx_x10_miss)):\n",
    "                x = int(random_indx_x10_miss[i])\n",
    "                list_result_D_3.append(D_svd_knn[y][x])\n",
    "                list_result_D_2.append(D_approx[y][x])\n",
    "            \n",
    "        m=100\n",
    "        n=150\n",
    "        result_D = ADMM(tmp_arr, frac_anomaly, frac_missing, random_indx_y10_miss, random_indx_x10_miss, m, n)\n",
    "        for i in range(len(random_indx_y10_miss)):\n",
    "            y = int(random_indx_y10_miss[i])\n",
    "            for i in range(len(random_indx_x10_miss)):\n",
    "                x = int(random_indx_x10_miss[i])\n",
    "                list_result_D.append(result_D[y][x])         \n",
    "        \n",
    "        raznost = [x - y for x, y in zip(list_D, list_result_D)]\n",
    "        raznost_2 = [x - y for x, y in zip(list_D, list_result_D_2)]\n",
    "        raznost_3 = [x - y for x, y in zip(list_D, list_result_D_3)]\n",
    "        new_nmae_err_list.append(np.mean(np.abs(raznost) / np.nanmean(np.abs(list_D))))\n",
    "        new_nmae_err_list_2.append(np.mean(np.abs(raznost_2) / np.nanmean(np.abs(list_D))))\n",
    "        new_nmae_err_list_3.append(np.mean(np.abs(raznost_3) / np.nanmean(np.abs(list_D))))\n",
    "    \n",
    "    new_loss_result_list.append(np.mean(new_nmae_err_list))\n",
    "    new_loss_result_list_2.append(np.mean(new_nmae_err_list_2))\n",
    "    new_loss_result_list_3.append(np.mean(new_nmae_err_list_3))   \n",
    "\n",
    "print(new_loss_result_list)\n",
    "print(new_loss_result_list_2)\n",
    "print(new_loss_result_list_3)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a80102f-63a5-4ecc-80d5-9395900a4489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n",
      "Iteration 30\n",
      "Iteration 31\n",
      "Iteration 32\n",
      "Iteration 33\n",
      "Iteration 34\n",
      "Iteration 35\n",
      "Iteration 36\n",
      "Iteration 37\n",
      "Iteration 38\n",
      "Iteration 39\n",
      "Iteration 40\n",
      "Iteration 41\n",
      "Iteration 42\n",
      "Iteration 43\n",
      "Iteration 44\n",
      "Iteration 45\n",
      "Iteration 46\n",
      "Iteration 47\n",
      "Iteration 48\n",
      "Iteration 49\n",
      "Iteration 50\n",
      "Iteration 51\n",
      "Iteration 52\n",
      "Iteration 53\n",
      "Iteration 54\n",
      "Iteration 55\n",
      "Iteration 56\n",
      "Iteration 57\n",
      "Iteration 58\n",
      "Iteration 59\n",
      "Iteration 60\n",
      "Iteration 61\n",
      "Iteration 62\n",
      "Iteration 63\n",
      "Iteration 64\n",
      "Iteration 65\n",
      "Iteration 66\n",
      "Iteration 67\n",
      "Iteration 68\n",
      "Iteration 69\n",
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n",
      "Iteration 30\n",
      "Iteration 31\n",
      "Iteration 32\n",
      "Iteration 33\n",
      "Iteration 34\n",
      "Iteration 35\n",
      "Iteration 36\n",
      "Iteration 37\n",
      "Iteration 38\n",
      "Iteration 39\n",
      "Iteration 40\n",
      "Iteration 41\n",
      "Iteration 42\n",
      "Iteration 43\n",
      "Iteration 44\n",
      "Iteration 45\n",
      "Iteration 46\n",
      "Iteration 47\n",
      "Iteration 48\n",
      "Iteration 49\n",
      "Iteration 50\n",
      "Iteration 51\n",
      "Iteration 52\n",
      "Iteration 53\n",
      "Iteration 54\n",
      "Iteration 55\n",
      "Iteration 56\n",
      "Iteration 57\n",
      "Iteration 58\n",
      "Iteration 59\n",
      "Iteration 60\n",
      "Iteration 61\n",
      "Iteration 62\n",
      "Iteration 63\n",
      "Iteration 64\n",
      "Iteration 65\n",
      "Iteration 66\n",
      "Iteration 67\n",
      "Iteration 68\n",
      "Iteration 69\n",
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n",
      "Iteration 30\n",
      "Iteration 31\n",
      "Iteration 32\n",
      "Iteration 33\n",
      "Iteration 34\n",
      "Iteration 35\n",
      "Iteration 36\n",
      "Iteration 37\n",
      "Iteration 38\n",
      "Iteration 39\n",
      "Iteration 40\n",
      "Iteration 41\n",
      "Iteration 42\n",
      "Iteration 43\n",
      "Iteration 44\n",
      "Iteration 45\n",
      "Iteration 46\n",
      "Iteration 47\n",
      "Iteration 48\n",
      "Iteration 49\n",
      "Iteration 50\n",
      "Iteration 51\n",
      "Iteration 52\n",
      "Iteration 53\n",
      "Iteration 54\n",
      "Iteration 55\n",
      "Iteration 56\n",
      "Iteration 57\n",
      "Iteration 58\n",
      "Iteration 59\n",
      "Iteration 60\n",
      "Iteration 61\n",
      "Iteration 62\n",
      "Iteration 63\n",
      "Iteration 64\n",
      "Iteration 65\n",
      "Iteration 66\n",
      "Iteration 67\n",
      "Iteration 68\n",
      "Iteration 69\n",
      "[1.054640942619884, 1.0588585047084673, 1.056676006711606]\n",
      "[1.0511691757260744, 1.048937855177119, 1.0583324951013104]\n",
      "[0.6790028719226718, 0.6795271598328738, 0.7342193086708195]\n",
      "CPU times: user 8h 47min 21s, sys: 15min 22s, total: 9h 2min 44s\n",
      "Wall time: 2h 16min 28s\n",
      "Parser   : 5.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.impute import KNNImputer\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "df_ = df.copy(deep=True)\n",
    "D = np.asmatrix(df_)\n",
    "tmp_arr = copy.deepcopy(main_arr)\n",
    "frac_anomaly = round(100*150*0.1)//2\n",
    "#frac_anomaly = 0\n",
    "\n",
    "new_loss_result_list = []\n",
    "new_loss_result_list_2 = []\n",
    "new_loss_result_list_3 = []\n",
    "\n",
    "p_ = [0.2, 0.4, 0.8]\n",
    "anomaly_size = [0.5, 1, 2, 5]\n",
    "anomaly_ratio = [0, 0.05, 0.1, 0.2]\n",
    "loss_probability = [0.2, 0.4, 0.8]   #first technique\n",
    "loss = 0.2\n",
    "anomaly_r = 0.1\n",
    "anomaly_s = 1\n",
    "frac_anomaly = anomaly_r\n",
    "\n",
    "for p in p_:\n",
    "#for anomaly_r in anomaly_ratio:\n",
    "#for anomaly_s in anomaly_size:\n",
    "#for loss in loss_probability:\n",
    "    new_nmae_err_list = []\n",
    "    new_nmae_err_list_2 = []\n",
    "    new_nmae_err_list_3 = []\n",
    "    nmae_err_list = []\n",
    "    nmae_err_list_2 = []\n",
    "    nmae_err_list_3 = []\n",
    "    frac_missing = round(100*150*loss)\n",
    "    #frac_anomaly = round(100*150*loss)\n",
    "    for i in range(1):\n",
    "#         #first technique\n",
    "        # random_indx_y10_miss = np.random.randint(0, 100, size=round(100*150*loss))\n",
    "        # random_indx_x10_miss = np.random.randint(0, 150, size=round(100*150*loss))\n",
    "        \n",
    "        #second technique\n",
    "        # random_indx_y10_miss = np.random.randint(0, 100, size=round(100*150*0.5))\n",
    "        # random_indx_x10_miss = np.random.randint(0, 150, size=round(100*150*p))\n",
    "        \n",
    "#         #third technique\n",
    "        random_indx_y10_miss = np.random.randint(0, 100, size=round(100*150*p))\n",
    "        random_indx_x10_miss = np.random.randint(0, 150, size=round(100*150*0.5))\n",
    "\n",
    "#         #fourth technique\n",
    "#         random_indx_y10_miss = np.array([i for i in range(100)])\n",
    "#         random_indx_x10_miss = np.random.randint(0, 150, size=round(100*150*loss))\n",
    "        \n",
    "#         #fifth technique\n",
    "#         random_indx_y10_miss = np.random.randint(0, 100, size=round(100*150*loss))\n",
    "#         random_indx_x10_miss = np.array([i for i in range(150)])\n",
    "      \n",
    "        list_D = []\n",
    "        list_result_D = []\n",
    "        list_result_D_2 = []\n",
    "        list_result_D_3 = []\n",
    "        tmp_arr = copy.deepcopy(main_arr)\n",
    "        for i in range(len(random_indx_y10_miss)):\n",
    "            y = int(random_indx_y10_miss[i])\n",
    "            for i in range(len(random_indx_x10_miss)):\n",
    "                x = int(random_indx_x10_miss[i])\n",
    "                list_D.append(main_arr[y][x])\n",
    "                tmp_arr[y][x] = None\n",
    "        \n",
    "        mean = np.nanmean(tmp_arr)\n",
    "        tmp_arr_for_svd = copy.deepcopy(tmp_arr)\n",
    "        tmp_arr_for_svd[np.isnan(tmp_arr_for_svd)] = 0\n",
    "        \n",
    "        indices = np.nonzero(np.isnan(tmp_arr_for_svd)) \n",
    "        random_indx_y10_anomal = np.random.randint(0, 100, size=round(100*150*anomaly_r))\n",
    "        random_indx_x10_anomal = np.random.randint(0, 150, size=round(100*150*anomaly_r))\n",
    "    \n",
    "        for i in range(len(random_indx_y10_anomal)):\n",
    "            y = int(random_indx_y10_anomal[i])\n",
    "            x = int(random_indx_x10_anomal[i])\n",
    "            tmp_arr[y][x] += s_1*anomaly_s\n",
    "            tmp_arr_for_svd[y][x] += s_1*anomaly_s\n",
    "        \n",
    "        U, sigma, V = np.linalg.svd(tmp_arr_for_svd)\n",
    "        # Выберем только первые две компоненты для аппроксимации\n",
    "        U = U[:, :2]\n",
    "        sigma = np.diag(sigma[:2])\n",
    "        V = V[:2, :]\n",
    "        # Вычислим аппроксимированную матрицу\n",
    "        D_approx = U @ sigma @ V\n",
    "\n",
    "        # Применяем K ближайших соседей для локальной интерполяции:\n",
    "        knn = KNeighborsRegressor(n_neighbors=2)\n",
    "        matrix_interp = knn.fit(D_approx, main_arr).predict(D_approx)\n",
    "\n",
    "        # Получаем итоговую матрицу, заменяя пропущенные значения после локальной интерполяции:\n",
    "        D_svd_knn = copy.deepcopy(tmp_arr)\n",
    "        D_svd_knn[np.isnan(D_svd_knn)] = matrix_interp[np.isnan(D_svd_knn)]\n",
    "        for i in range(len(random_indx_y10_miss)):\n",
    "            y = int(random_indx_y10_miss[i])\n",
    "            for i in range(len(random_indx_x10_miss)):\n",
    "                x = int(random_indx_x10_miss[i])\n",
    "                list_result_D_3.append(D_svd_knn[y][x])\n",
    "                list_result_D_2.append(D_approx[y][x])\n",
    "            \n",
    "        m=100\n",
    "        n=150\n",
    "        result_D = ADMM(tmp_arr, frac_anomaly, frac_missing, random_indx_y10_miss, random_indx_x10_miss, m, n)\n",
    "        for i in range(len(random_indx_y10_miss)):\n",
    "            y = int(random_indx_y10_miss[i])\n",
    "            for i in range(len(random_indx_x10_miss)):\n",
    "                x = int(random_indx_x10_miss[i])\n",
    "                list_result_D.append(result_D[y][x])      \n",
    "        \n",
    "        raznost = [x - y for x, y in zip(list_D, list_result_D)]\n",
    "        raznost_2 = [x - y for x, y in zip(list_D, list_result_D_2)]\n",
    "        raznost_3 = [x - y for x, y in zip(list_D, list_result_D_3)]\n",
    "        new_nmae_err_list.append(np.mean(np.abs(raznost) / np.nanmean(np.abs(list_D))))\n",
    "        new_nmae_err_list_2.append(np.mean(np.abs(raznost_2) / np.nanmean(np.abs(list_D))))\n",
    "        new_nmae_err_list_3.append(np.mean(np.abs(raznost_3) / np.nanmean(np.abs(list_D))))\n",
    "    \n",
    "    new_loss_result_list.append(np.mean(new_nmae_err_list))\n",
    "    new_loss_result_list_2.append(np.mean(new_nmae_err_list_2))\n",
    "    new_loss_result_list_3.append(np.mean(new_nmae_err_list_3))   \n",
    "\n",
    "print(new_loss_result_list)\n",
    "print(new_loss_result_list_2)\n",
    "print(new_loss_result_list_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "529dcf2e-f0bf-4f3d-a115-a049c91ccd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n",
      "Iteration 30\n",
      "Iteration 31\n",
      "Iteration 32\n",
      "Iteration 33\n",
      "Iteration 34\n",
      "Iteration 35\n",
      "Iteration 36\n",
      "Iteration 37\n",
      "Iteration 38\n",
      "Iteration 39\n",
      "Iteration 40\n",
      "Iteration 41\n",
      "Iteration 42\n",
      "Iteration 43\n",
      "Iteration 44\n",
      "Iteration 45\n",
      "Iteration 46\n",
      "Iteration 47\n",
      "Iteration 48\n",
      "Iteration 49\n",
      "Iteration 50\n",
      "Iteration 51\n",
      "Iteration 52\n",
      "Iteration 53\n",
      "Iteration 54\n",
      "Iteration 55\n",
      "Iteration 56\n",
      "Iteration 57\n",
      "Iteration 58\n",
      "Iteration 59\n",
      "Iteration 60\n",
      "Iteration 61\n",
      "Iteration 62\n",
      "Iteration 63\n",
      "Iteration 64\n",
      "Iteration 65\n",
      "Iteration 66\n",
      "Iteration 67\n",
      "Iteration 68\n",
      "Iteration 69\n",
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n",
      "Iteration 30\n",
      "Iteration 31\n",
      "Iteration 32\n",
      "Iteration 33\n",
      "Iteration 34\n",
      "Iteration 35\n",
      "Iteration 36\n",
      "Iteration 37\n",
      "Iteration 38\n",
      "Iteration 39\n",
      "Iteration 40\n",
      "Iteration 41\n",
      "Iteration 42\n",
      "Iteration 43\n",
      "Iteration 44\n",
      "Iteration 45\n",
      "Iteration 46\n",
      "Iteration 47\n",
      "Iteration 48\n",
      "Iteration 49\n",
      "Iteration 50\n",
      "Iteration 51\n",
      "Iteration 52\n",
      "Iteration 53\n",
      "Iteration 54\n",
      "Iteration 55\n",
      "Iteration 56\n",
      "Iteration 57\n",
      "Iteration 58\n",
      "Iteration 59\n",
      "Iteration 60\n",
      "Iteration 61\n",
      "Iteration 62\n",
      "Iteration 63\n",
      "Iteration 64\n",
      "Iteration 65\n",
      "Iteration 66\n",
      "Iteration 67\n",
      "Iteration 68\n",
      "Iteration 69\n",
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n",
      "Iteration 30\n",
      "Iteration 31\n",
      "Iteration 32\n",
      "Iteration 33\n",
      "Iteration 34\n",
      "Iteration 35\n",
      "Iteration 36\n",
      "Iteration 37\n",
      "Iteration 38\n",
      "Iteration 39\n",
      "Iteration 40\n",
      "Iteration 41\n",
      "Iteration 42\n",
      "Iteration 43\n",
      "Iteration 44\n",
      "Iteration 45\n",
      "Iteration 46\n",
      "Iteration 47\n",
      "Iteration 48\n",
      "Iteration 49\n",
      "Iteration 50\n",
      "Iteration 51\n",
      "Iteration 52\n",
      "Iteration 53\n",
      "Iteration 54\n",
      "Iteration 55\n",
      "Iteration 56\n",
      "Iteration 57\n",
      "Iteration 58\n",
      "Iteration 59\n",
      "Iteration 60\n",
      "Iteration 61\n",
      "Iteration 62\n",
      "Iteration 63\n",
      "Iteration 64\n",
      "Iteration 65\n",
      "Iteration 66\n",
      "Iteration 67\n",
      "Iteration 68\n",
      "Iteration 69\n",
      "[1.056033573773137, 1.0573351124021448, 1.0606703633608643]\n",
      "[1.0598162751128521, 1.0592866732389825, 1.0526415268306353]\n",
      "[0.6947093626936793, 0.6851476311381169, 0.7000319996198895]\n"
     ]
    }
   ],
   "source": [
    "df_ = df.copy(deep=True)\n",
    "D = np.asmatrix(df_)\n",
    "tmp_arr = copy.deepcopy(main_arr)\n",
    "frac_anomaly = round(100*150*0.1)//2\n",
    "#frac_anomaly = 0\n",
    "new_loss_result_list = []\n",
    "new_loss_result_list_2 = []\n",
    "new_loss_result_list_3 = []\n",
    "\n",
    "p_ = [0.2, 0.4, 0.8]\n",
    "anomaly_size = [0.5, 1, 2, 5]\n",
    "anomaly_ratio = [0, 0.05, 0.1, 0.2]\n",
    "loss_probability = [0.2, 0.4, 0.8]   #first technique\n",
    "loss = 0.2\n",
    "anomaly_r = 0.1\n",
    "anomaly_s = 1\n",
    "frac_anomaly = anomaly_r\n",
    "\n",
    "for p in p_:\n",
    "#for anomaly_r in anomaly_ratio:\n",
    "#for anomaly_s in anomaly_size:\n",
    "#for loss in loss_probability:\n",
    "    new_nmae_err_list = []\n",
    "    new_nmae_err_list_2 = []\n",
    "    new_nmae_err_list_3 = []\n",
    "    nmae_err_list = []\n",
    "    nmae_err_list_2 = []\n",
    "    nmae_err_list_3 = []\n",
    "    frac_missing = round(100*150*loss)\n",
    "    #frac_anomaly = round(100*150*loss)\n",
    "    for i in range(1):\n",
    "#         #first technique\n",
    "        # random_indx_y10_miss = np.random.randint(0, 100, size=round(100*150*loss))\n",
    "        # random_indx_x10_miss = np.random.randint(0, 150, size=round(100*150*loss))\n",
    "        \n",
    "        #second technique\n",
    "        # random_indx_y10_miss = np.random.randint(0, 100, size=round(100*150*0.5))\n",
    "        # random_indx_x10_miss = np.random.randint(0, 150, size=round(100*150*p))\n",
    "        \n",
    "#         #third technique\n",
    "        # random_indx_y10_miss = np.random.randint(0, 100, size=round(100*150*p))\n",
    "        # random_indx_x10_miss = np.random.randint(0, 150, size=round(100*150*0.5))\n",
    "\n",
    "#         #fourth technique\n",
    "        random_indx_y10_miss = np.array([i for i in range(100)])\n",
    "        random_indx_x10_miss = np.random.randint(0, 150, size=round(100*150*loss))\n",
    "        \n",
    "#         #fifth technique\n",
    "#         random_indx_y10_miss = np.random.randint(0, 100, size=round(100*150*loss))\n",
    "#         random_indx_x10_miss = np.array([i for i in range(150)])\n",
    "      \n",
    "        list_D = []\n",
    "        list_result_D = []\n",
    "        list_result_D_2 = []\n",
    "        list_result_D_3 = []\n",
    "        tmp_arr = copy.deepcopy(main_arr)\n",
    "        for i in range(len(random_indx_y10_miss)):\n",
    "            y = int(random_indx_y10_miss[i])\n",
    "            for i in range(len(random_indx_x10_miss)):\n",
    "                x = int(random_indx_x10_miss[i])\n",
    "                list_D.append(main_arr[y][x])\n",
    "                tmp_arr[y][x] = None\n",
    "        \n",
    "        #print(list_D)\n",
    "        mean = np.nanmean(tmp_arr)\n",
    "        tmp_arr_for_svd = copy.deepcopy(tmp_arr)\n",
    "        tmp_arr_for_svd[np.isnan(tmp_arr_for_svd)] = 0\n",
    "        \n",
    "        indices = np.nonzero(np.isnan(tmp_arr_for_svd)) \n",
    "        random_indx_y10_anomal = np.random.randint(0, 100, size=round(100*150*anomaly_r))\n",
    "        random_indx_x10_anomal = np.random.randint(0, 150, size=round(100*150*anomaly_r))\n",
    "    \n",
    "        for i in range(len(random_indx_y10_anomal)):\n",
    "            y = int(random_indx_y10_anomal[i])\n",
    "            x = int(random_indx_x10_anomal[i])\n",
    "            tmp_arr[y][x] += s_1*anomaly_s\n",
    "            tmp_arr_for_svd[y][x] += s_1*anomaly_s\n",
    "        \n",
    "        U, sigma, V = np.linalg.svd(tmp_arr_for_svd)\n",
    "        # Выберем только первые две компоненты для аппроксимации\n",
    "        U = U[:, :2]\n",
    "        sigma = np.diag(sigma[:2])\n",
    "        V = V[:2, :]\n",
    "        # Вычислим аппроксимированную матрицу\n",
    "        D_approx = U @ sigma @ V\n",
    "        #print(D_approx)\n",
    "\n",
    "        # Применяем K ближайших соседей для локальной интерполяции:\n",
    "        knn = KNeighborsRegressor(n_neighbors=2)\n",
    "        matrix_interp = knn.fit(D_approx, main_arr).predict(D_approx)\n",
    "\n",
    "        # Получаем итоговую матрицу, заменяя пропущенные значения после локальной интерполяции:\n",
    "        D_svd_knn = copy.deepcopy(tmp_arr)\n",
    "        D_svd_knn[np.isnan(D_svd_knn)] = matrix_interp[np.isnan(D_svd_knn)]\n",
    "        for i in range(len(random_indx_y10_miss)):\n",
    "            y = int(random_indx_y10_miss[i])\n",
    "            for i in range(len(random_indx_x10_miss)):\n",
    "                x = int(random_indx_x10_miss[i])\n",
    "                list_result_D_3.append(D_svd_knn[y][x])\n",
    "                list_result_D_2.append(D_approx[y][x])\n",
    "            \n",
    "        m=100\n",
    "        n=150\n",
    "        result_D = ADMM(tmp_arr, frac_anomaly, frac_missing, random_indx_y10_miss, random_indx_x10_miss, m, n)\n",
    "        for i in range(len(random_indx_y10_miss)):\n",
    "            y = int(random_indx_y10_miss[i])\n",
    "            for i in range(len(random_indx_x10_miss)):\n",
    "                x = int(random_indx_x10_miss[i])\n",
    "                list_result_D.append(result_D[y][x])   \n",
    "        \n",
    "        raznost = [x - y for x, y in zip(list_D, list_result_D)]\n",
    "        raznost_2 = [x - y for x, y in zip(list_D, list_result_D_2)]\n",
    "        raznost_3 = [x - y for x, y in zip(list_D, list_result_D_3)]\n",
    "        new_nmae_err_list.append(np.mean(np.abs(raznost) / np.nanmean(np.abs(list_D))))\n",
    "        new_nmae_err_list_2.append(np.mean(np.abs(raznost_2) / np.nanmean(np.abs(list_D))))\n",
    "        new_nmae_err_list_3.append(np.mean(np.abs(raznost_3) / np.nanmean(np.abs(list_D))))\n",
    "    \n",
    "    new_loss_result_list.append(np.mean(new_nmae_err_list))\n",
    "    new_loss_result_list_2.append(np.mean(new_nmae_err_list_2))\n",
    "    new_loss_result_list_3.append(np.mean(new_nmae_err_list_3))   \n",
    "\n",
    "print(new_loss_result_list)\n",
    "print(new_loss_result_list_2)\n",
    "print(new_loss_result_list_3)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "393c4378-f836-44ee-bb3a-c6a9bccdeb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n",
      "Iteration 30\n",
      "Iteration 31\n",
      "Iteration 32\n",
      "Iteration 33\n",
      "Iteration 34\n",
      "Iteration 35\n",
      "Iteration 36\n",
      "Iteration 37\n",
      "Iteration 38\n",
      "Iteration 39\n",
      "Iteration 40\n",
      "Iteration 41\n",
      "Iteration 42\n",
      "Iteration 43\n",
      "Iteration 44\n",
      "Iteration 45\n",
      "Iteration 46\n",
      "Iteration 47\n",
      "Iteration 48\n",
      "Iteration 49\n",
      "Iteration 50\n",
      "Iteration 51\n",
      "Iteration 52\n",
      "Iteration 53\n",
      "Iteration 54\n",
      "Iteration 55\n",
      "Iteration 56\n",
      "Iteration 57\n",
      "Iteration 58\n",
      "Iteration 59\n",
      "Iteration 60\n",
      "Iteration 61\n",
      "Iteration 62\n",
      "Iteration 63\n",
      "Iteration 64\n",
      "Iteration 65\n",
      "Iteration 66\n",
      "Iteration 67\n",
      "Iteration 68\n",
      "Iteration 69\n",
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n",
      "Iteration 30\n",
      "Iteration 31\n",
      "Iteration 32\n",
      "Iteration 33\n",
      "Iteration 34\n",
      "Iteration 35\n",
      "Iteration 36\n",
      "Iteration 37\n",
      "Iteration 38\n",
      "Iteration 39\n",
      "Iteration 40\n",
      "Iteration 41\n",
      "Iteration 42\n",
      "Iteration 43\n",
      "Iteration 44\n",
      "Iteration 45\n",
      "Iteration 46\n",
      "Iteration 47\n",
      "Iteration 48\n",
      "Iteration 49\n",
      "Iteration 50\n",
      "Iteration 51\n",
      "Iteration 52\n",
      "Iteration 53\n",
      "Iteration 54\n",
      "Iteration 55\n",
      "Iteration 56\n",
      "Iteration 57\n",
      "Iteration 58\n",
      "Iteration 59\n",
      "Iteration 60\n",
      "Iteration 61\n",
      "Iteration 62\n",
      "Iteration 63\n",
      "Iteration 64\n",
      "Iteration 65\n",
      "Iteration 66\n",
      "Iteration 67\n",
      "Iteration 68\n",
      "Iteration 69\n",
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n",
      "Iteration 30\n",
      "Iteration 31\n",
      "Iteration 32\n",
      "Iteration 33\n",
      "Iteration 34\n",
      "Iteration 35\n",
      "Iteration 36\n",
      "Iteration 37\n",
      "Iteration 38\n",
      "Iteration 39\n",
      "Iteration 40\n",
      "Iteration 41\n",
      "Iteration 42\n",
      "Iteration 43\n",
      "Iteration 44\n",
      "Iteration 45\n",
      "Iteration 46\n",
      "Iteration 47\n",
      "Iteration 48\n",
      "Iteration 49\n",
      "Iteration 50\n",
      "Iteration 51\n",
      "Iteration 52\n",
      "Iteration 53\n",
      "Iteration 54\n",
      "Iteration 55\n",
      "Iteration 56\n",
      "Iteration 57\n",
      "Iteration 58\n",
      "Iteration 59\n",
      "Iteration 60\n",
      "Iteration 61\n",
      "Iteration 62\n",
      "Iteration 63\n",
      "Iteration 64\n",
      "Iteration 65\n",
      "Iteration 66\n",
      "Iteration 67\n",
      "Iteration 68\n",
      "Iteration 69\n",
      "[1.055345239204295, 1.0586987328197195, 1.0579937914533692]\n",
      "[1.0550556963591682, 1.0661021692544692, 1.0594642969461523]\n",
      "[0.6745943870394626, 0.7480537036973214, 0.674862856763629]\n"
     ]
    }
   ],
   "source": [
    "df_ = df.copy(deep=True)\n",
    "D = np.asmatrix(df_)\n",
    "tmp_arr = copy.deepcopy(main_arr)\n",
    "frac_anomaly = round(100*150*0.1)//2\n",
    "#frac_anomaly = 0\n",
    "new_loss_result_list = []\n",
    "new_loss_result_list_2 = []\n",
    "new_loss_result_list_3 = []\n",
    "\n",
    "p_ = [0.2, 0.4, 0.8]\n",
    "anomaly_size = [0.5, 1, 2, 5]\n",
    "anomaly_ratio = [0, 0.05, 0.1, 0.2]\n",
    "loss_probability = [0.2, 0.4, 0.8]   #first technique\n",
    "#loss_probability = [0.2]\n",
    "loss = 0.2\n",
    "anomaly_r = 0.1\n",
    "anomaly_s = 1\n",
    "frac_anomaly = anomaly_r\n",
    "\n",
    "for p in p_:\n",
    "#for anomaly_r in anomaly_ratio:\n",
    "#for anomaly_s in anomaly_size:\n",
    "#for loss in loss_probability:\n",
    "    new_nmae_err_list = []\n",
    "    new_nmae_err_list_2 = []\n",
    "    new_nmae_err_list_3 = []\n",
    "    nmae_err_list = []\n",
    "    nmae_err_list_2 = []\n",
    "    nmae_err_list_3 = []\n",
    "    frac_missing = round(100*150*loss)\n",
    "    #frac_anomaly = round(100*150*loss)\n",
    "    for i in range(1):\n",
    "#         #first technique\n",
    "        # random_indx_y10_miss = np.random.randint(0, 100, size=round(100*150*loss))\n",
    "        # random_indx_x10_miss = np.random.randint(0, 150, size=round(100*150*loss))\n",
    "        \n",
    "        #second technique\n",
    "        # random_indx_y10_miss = np.random.randint(0, 100, size=round(100*150*0.5))\n",
    "        # random_indx_x10_miss = np.random.randint(0, 150, size=round(100*150*p))\n",
    "        \n",
    "#         #third technique\n",
    "        # random_indx_y10_miss = np.random.randint(0, 100, size=round(100*150*p))\n",
    "        # random_indx_x10_miss = np.random.randint(0, 150, size=round(100*150*0.5))\n",
    "\n",
    "#         #fourth technique\n",
    "#         random_indx_y10_miss = np.array([i for i in range(100)])\n",
    "#         random_indx_x10_miss = np.random.randint(0, 150, size=round(100*150*loss))\n",
    "        \n",
    "#         #fifth technique\n",
    "        random_indx_y10_miss = np.random.randint(0, 100, size=round(100*150*loss))\n",
    "        random_indx_x10_miss = np.array([i for i in range(150)])\n",
    "      \n",
    "        list_D = []\n",
    "        list_result_D = []\n",
    "        list_result_D_2 = []\n",
    "        list_result_D_3 = []\n",
    "        tmp_arr = copy.deepcopy(main_arr)\n",
    "        for i in range(len(random_indx_x10_miss)):\n",
    "            x = int(random_indx_x10_miss[i])\n",
    "            for i in range(len(random_indx_y10_miss)):\n",
    "                y = int(random_indx_y10_miss[i])\n",
    "                #print(tmp_arr[y][x])\n",
    "                list_D.append(main_arr[y][x])\n",
    "                tmp_arr[y][x] = None\n",
    "        \n",
    "        mean = np.nanmean(tmp_arr)\n",
    "        tmp_arr_for_svd = copy.deepcopy(tmp_arr)\n",
    "        tmp_arr_for_svd[np.isnan(tmp_arr_for_svd)] = 0\n",
    "        \n",
    "        indices = np.nonzero(np.isnan(tmp_arr_for_svd))\n",
    "  \n",
    "        random_indx_y10_anomal = np.random.randint(0, 100, size=round(100*150*anomaly_r))\n",
    "        random_indx_x10_anomal = np.random.randint(0, 150, size=round(100*150*anomaly_r))\n",
    "    \n",
    "        for i in range(len(random_indx_y10_anomal)):\n",
    "            y = int(random_indx_y10_anomal[i])\n",
    "            x = int(random_indx_x10_anomal[i])\n",
    "            tmp_arr[y][x] += s_1*anomaly_s\n",
    "            tmp_arr_for_svd[y][x] += s_1*anomaly_s\n",
    "        \n",
    "        U, sigma, V = np.linalg.svd(tmp_arr_for_svd)\n",
    "        # Выберем только первые две компоненты для аппроксимации\n",
    "        U = U[:, :2]\n",
    "        sigma = np.diag(sigma[:2])\n",
    "        V = V[:2, :]\n",
    "        # Вычислим аппроксимированную матрицу\n",
    "        D_approx = U @ sigma @ V\n",
    "\n",
    "        # Применяем K ближайших соседей для локальной интерполяции:\n",
    "        knn = KNeighborsRegressor(n_neighbors=2)\n",
    "        matrix_interp = knn.fit(D_approx, main_arr).predict(D_approx)\n",
    "\n",
    "        # Получаем итоговую матрицу, заменяя пропущенные значения после локальной интерполяции:\n",
    "        D_svd_knn = copy.deepcopy(tmp_arr)\n",
    "        D_svd_knn[np.isnan(D_svd_knn)] = matrix_interp[np.isnan(D_svd_knn)]\n",
    "        for i in range(len(random_indx_x10_miss)):\n",
    "            x = int(random_indx_x10_miss[i])\n",
    "            for i in range(len(random_indx_y10_miss)):\n",
    "                y = int(random_indx_y10_miss[i])\n",
    "                list_result_D_3.append(D_svd_knn[y][x])\n",
    "                list_result_D_2.append(D_approx[y][x])\n",
    "            \n",
    "        m=100\n",
    "        n=150\n",
    "        result_D = ADMM(tmp_arr, frac_anomaly, frac_missing, random_indx_y10_miss, random_indx_x10_miss, m, n)\n",
    "        for i in range(len(random_indx_x10_miss)):\n",
    "            x = int(random_indx_x10_miss[i])\n",
    "            for i in range(len(random_indx_y10_miss)):\n",
    "                y = int(random_indx_y10_miss[i])\n",
    "                list_result_D.append(result_D[y][x])       \n",
    "        \n",
    "        raznost = [x - y for x, y in zip(list_D, list_result_D)]\n",
    "        raznost_2 = [x - y for x, y in zip(list_D, list_result_D_2)]\n",
    "        raznost_3 = [x - y for x, y in zip(list_D, list_result_D_3)]\n",
    "        new_nmae_err_list.append(np.mean(np.abs(raznost) / np.nanmean(np.abs(list_D))))\n",
    "        new_nmae_err_list_2.append(np.mean(np.abs(raznost_2) / np.nanmean(np.abs(list_D))))\n",
    "        new_nmae_err_list_3.append(np.mean(np.abs(raznost_3) / np.nanmean(np.abs(list_D))))\n",
    "    \n",
    "    new_loss_result_list.append(np.mean(new_nmae_err_list))\n",
    "    new_loss_result_list_2.append(np.mean(new_nmae_err_list_2))\n",
    "    new_loss_result_list_3.append(np.mean(new_nmae_err_list_3))   \n",
    "\n",
    "print(new_loss_result_list)\n",
    "print(new_loss_result_list_2)\n",
    "print(new_loss_result_list_3)        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33b53201-1797-405f-ab0b-6859041bc4b0",
   "metadata": {},
   "source": [
    "Вариация размера аномалий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb8e77a0-06ea-42d3-b35b-8077aec9c38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n",
      "Iteration 30\n",
      "Iteration 31\n",
      "Iteration 32\n",
      "Iteration 33\n",
      "Iteration 34\n",
      "Iteration 35\n",
      "Iteration 36\n",
      "Iteration 37\n",
      "Iteration 38\n",
      "Iteration 39\n",
      "Iteration 40\n",
      "Iteration 41\n",
      "Iteration 42\n",
      "Iteration 43\n",
      "Iteration 44\n",
      "Iteration 45\n",
      "Iteration 46\n",
      "Iteration 47\n",
      "Iteration 48\n",
      "Iteration 49\n",
      "Iteration 50\n",
      "Iteration 51\n",
      "Iteration 52\n",
      "Iteration 53\n",
      "Iteration 54\n",
      "Iteration 55\n",
      "Iteration 56\n",
      "Iteration 57\n",
      "Iteration 58\n",
      "Iteration 59\n",
      "Iteration 60\n",
      "Iteration 61\n",
      "Iteration 62\n",
      "Iteration 63\n",
      "Iteration 64\n",
      "Iteration 65\n",
      "Iteration 66\n",
      "Iteration 67\n",
      "Iteration 68\n",
      "Iteration 69\n",
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n",
      "Iteration 30\n",
      "Iteration 31\n",
      "Iteration 32\n",
      "Iteration 33\n",
      "Iteration 34\n",
      "Iteration 35\n",
      "Iteration 36\n",
      "Iteration 37\n",
      "Iteration 38\n",
      "Iteration 39\n",
      "Iteration 40\n",
      "Iteration 41\n",
      "Iteration 42\n",
      "Iteration 43\n",
      "Iteration 44\n",
      "Iteration 45\n",
      "Iteration 46\n",
      "Iteration 47\n",
      "Iteration 48\n",
      "Iteration 49\n",
      "Iteration 50\n",
      "Iteration 51\n",
      "Iteration 52\n",
      "Iteration 53\n",
      "Iteration 54\n",
      "Iteration 55\n",
      "Iteration 56\n",
      "Iteration 57\n",
      "Iteration 58\n",
      "Iteration 59\n",
      "Iteration 60\n",
      "Iteration 61\n",
      "Iteration 62\n",
      "Iteration 63\n",
      "Iteration 64\n",
      "Iteration 65\n",
      "Iteration 66\n",
      "Iteration 67\n",
      "Iteration 68\n",
      "Iteration 69\n",
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n",
      "Iteration 30\n",
      "Iteration 31\n",
      "Iteration 32\n",
      "Iteration 33\n",
      "Iteration 34\n",
      "Iteration 35\n",
      "Iteration 36\n",
      "Iteration 37\n",
      "Iteration 38\n",
      "Iteration 39\n",
      "Iteration 40\n",
      "Iteration 41\n",
      "Iteration 42\n",
      "Iteration 43\n",
      "Iteration 44\n",
      "Iteration 45\n",
      "Iteration 46\n",
      "Iteration 47\n",
      "Iteration 48\n",
      "Iteration 49\n",
      "Iteration 50\n",
      "Iteration 51\n",
      "Iteration 52\n",
      "Iteration 53\n",
      "Iteration 54\n",
      "Iteration 55\n",
      "Iteration 56\n",
      "Iteration 57\n",
      "Iteration 58\n",
      "Iteration 59\n",
      "Iteration 60\n",
      "Iteration 61\n",
      "Iteration 62\n",
      "Iteration 63\n",
      "Iteration 64\n",
      "Iteration 65\n",
      "Iteration 66\n",
      "Iteration 67\n",
      "Iteration 68\n",
      "Iteration 69\n",
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n",
      "Iteration 30\n",
      "Iteration 31\n",
      "Iteration 32\n",
      "Iteration 33\n",
      "Iteration 34\n",
      "Iteration 35\n",
      "Iteration 36\n",
      "Iteration 37\n",
      "Iteration 38\n",
      "Iteration 39\n",
      "Iteration 40\n",
      "Iteration 41\n",
      "Iteration 42\n",
      "Iteration 43\n",
      "Iteration 44\n",
      "Iteration 45\n",
      "Iteration 46\n",
      "Iteration 47\n",
      "Iteration 48\n",
      "Iteration 49\n",
      "Iteration 50\n",
      "Iteration 51\n",
      "Iteration 52\n",
      "Iteration 53\n",
      "Iteration 54\n",
      "Iteration 55\n",
      "Iteration 56\n",
      "Iteration 57\n",
      "Iteration 58\n",
      "Iteration 59\n",
      "Iteration 60\n",
      "Iteration 61\n",
      "Iteration 62\n",
      "Iteration 63\n",
      "Iteration 64\n",
      "Iteration 65\n",
      "Iteration 66\n",
      "Iteration 67\n",
      "Iteration 68\n",
      "Iteration 69\n",
      "[1.053327286632783, 1.0592144087004656, 1.056644814014344, 1.0636642505126777]\n",
      "[0.9105443496450363, 0.9264266284661986, 1.1782841790129908, 3.4223503804114563]\n",
      "[0.6195784061132575, 0.5798489037912227, 0.6495126427928257, 0.7459979718181541]\n",
      "CPU times: user 13h 59min 34s, sys: 23min 6s, total: 14h 22min 40s\n",
      "Wall time: 2h 54min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.impute import KNNImputer\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "df_ = df.copy(deep=True)\n",
    "D = np.asmatrix(df_)\n",
    "tmp_arr = copy.deepcopy(main_arr)\n",
    "\n",
    "new_loss_result_list = []\n",
    "new_loss_result_list_2 = []\n",
    "new_loss_result_list_3 = []\n",
    "\n",
    "p_ = [0.2, 0.4, 0.8]\n",
    "anomaly_size = [0.5, 1, 2, 5]\n",
    "anomaly_ratio = [0, 0.05, 0.1, 0.2]\n",
    "loss_probability = [0.2, 0.4, 0.8]   #first technique\n",
    "loss = 0.2\n",
    "anomaly_r = 0.1\n",
    "anomaly_s = 1\n",
    "frac_anomaly = anomaly_r\n",
    "#for p in p_:\n",
    "#for anomaly_r in anomaly_ratio:\n",
    "for anomaly_s in anomaly_size:\n",
    "#for loss in loss_probability:\n",
    "    new_nmae_err_list = []\n",
    "    new_nmae_err_list_2 = []\n",
    "    new_nmae_err_list_3 = []\n",
    "    nmae_err_list = []\n",
    "    nmae_err_list_2 = []\n",
    "    nmae_err_list_3 = []\n",
    "    frac_missing = round(100*150*loss)\n",
    "    for i in range(1):\n",
    "#         #first technique\n",
    "        random_indx_y10_miss = np.random.randint(0, 100, size=round(100*150*loss))\n",
    "        random_indx_x10_miss = np.random.randint(0, 150, size=round(100*150*loss))\n",
    "        \n",
    "        #second technique\n",
    "        # random_indx_y10_miss = np.random.randint(0, 100, size=round(100*150*0.5))\n",
    "        # random_indx_x10_miss = np.random.randint(0, 150, size=round(100*150*p))\n",
    "        \n",
    "#         #third technique\n",
    "        # random_indx_y10_miss = np.random.randint(0, 100, size=round(100*150*p))\n",
    "        # random_indx_x10_miss = np.random.randint(0, 150, size=round(100*150*0.5))\n",
    "\n",
    "#         #fourth technique\n",
    "#         random_indx_y10_miss = np.array([i for i in range(100)])\n",
    "#         random_indx_x10_miss = np.random.randint(0, 150, size=round(100*150*loss))\n",
    "        \n",
    "#         #fifth technique\n",
    "        # random_indx_y10_miss = np.random.randint(0, 100, size=round(100*150*loss))\n",
    "        # random_indx_x10_miss = np.array([i for i in range(150)])\n",
    "      \n",
    "        list_D = []\n",
    "        list_result_D = []\n",
    "        list_result_D_2 = []\n",
    "        list_result_D_3 = []\n",
    "        tmp_arr = copy.deepcopy(main_arr)\n",
    "\n",
    "        for i in range(len(random_indx_x10_miss)):\n",
    "            x = int(random_indx_x10_miss[i])\n",
    "            y = int(random_indx_y10_miss[i])\n",
    "            list_D.append(main_arr[y][x])\n",
    "            tmp_arr[y][x] = None\n",
    "\n",
    "        mean = np.nanmean(tmp_arr)\n",
    "        tmp_arr_for_svd = copy.deepcopy(tmp_arr)\n",
    "        tmp_arr_for_svd[np.isnan(tmp_arr_for_svd)] = 0\n",
    "        \n",
    "        indices = np.nonzero(np.isnan(tmp_arr_for_svd)) \n",
    "        random_indx_y10_anomal = np.random.randint(0, 100, size=round(100*150*anomaly_r))\n",
    "        random_indx_x10_anomal = np.random.randint(0, 150, size=round(100*150*anomaly_r))\n",
    "    \n",
    "        for i in range(len(random_indx_y10_anomal)):\n",
    "            y = int(random_indx_y10_anomal[i])\n",
    "            x = int(random_indx_x10_anomal[i])\n",
    "            tmp_arr[y][x] += s_1*anomaly_s\n",
    "            tmp_arr_for_svd[y][x] += s_1*anomaly_s\n",
    "        \n",
    "        U, sigma, V = np.linalg.svd(tmp_arr_for_svd)\n",
    "        # Выберем только первые две компоненты для аппроксимации\n",
    "        U = U[:, :2]\n",
    "        sigma = np.diag(sigma[:2])\n",
    "        V = V[:2, :]\n",
    "        # Вычислим аппроксимированную матрицу\n",
    "        D_approx = U @ sigma @ V\n",
    "\n",
    "        # Применяем K ближайших соседей для локальной интерполяции:\n",
    "        knn = KNeighborsRegressor(n_neighbors=2)\n",
    "        matrix_interp = knn.fit(D_approx, main_arr).predict(D_approx)\n",
    "\n",
    "        # Получаем итоговую матрицу, заменяя пропущенные значения после локальной интерполяции:\n",
    "        D_svd_knn = copy.deepcopy(tmp_arr)\n",
    "        D_svd_knn[np.isnan(D_svd_knn)] = matrix_interp[np.isnan(D_svd_knn)]\n",
    "\n",
    "        for i in range(len(random_indx_x10_miss)):\n",
    "            x = int(random_indx_x10_miss[i])\n",
    "            y = int(random_indx_y10_miss[i])\n",
    "            list_result_D_3.append(D_svd_knn[y][x])\n",
    "            list_result_D_2.append(D_approx[y][x])\n",
    "            \n",
    "        m=100\n",
    "        n=150\n",
    "        result_D = ADMM(tmp_arr, frac_anomaly, frac_missing, random_indx_y10_miss, random_indx_x10_miss, m, n)\n",
    "        for i in range(len(random_indx_x10_miss)):\n",
    "            x = int(random_indx_x10_miss[i])\n",
    "            y = int(random_indx_y10_miss[i])\n",
    "            list_result_D.append(result_D[y][x])       \n",
    "        \n",
    "        raznost = [x - y for x, y in zip(list_D, list_result_D)]\n",
    "        raznost_2 = [x - y for x, y in zip(list_D, list_result_D_2)]\n",
    "        raznost_3 = [x - y for x, y in zip(list_D, list_result_D_3)]\n",
    "        new_nmae_err_list.append(np.mean(np.abs(raznost) / np.nanmean(np.abs(list_D))))\n",
    "        new_nmae_err_list_2.append(np.mean(np.abs(raznost_2) / np.nanmean(np.abs(list_D))))\n",
    "        new_nmae_err_list_3.append(np.mean(np.abs(raznost_3) / np.nanmean(np.abs(list_D))))\n",
    "    \n",
    "    new_loss_result_list.append(np.mean(new_nmae_err_list))\n",
    "    new_loss_result_list_2.append(np.mean(new_nmae_err_list_2))\n",
    "    new_loss_result_list_3.append(np.mean(new_nmae_err_list_3))\n",
    "\n",
    "print(new_loss_result_list)\n",
    "print(new_loss_result_list_2)\n",
    "print(new_loss_result_list_3)        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0106cccf-4dd5-4694-aee8-31c601b17edd",
   "metadata": {},
   "source": [
    "Вариация доли аномалий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d4c094b-8aac-46b7-9649-f85ce525cc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n",
      "Iteration 30\n",
      "Iteration 31\n",
      "Iteration 32\n",
      "Iteration 33\n",
      "Iteration 34\n",
      "Iteration 35\n",
      "Iteration 36\n",
      "Iteration 37\n",
      "Iteration 38\n",
      "Iteration 39\n",
      "Iteration 40\n",
      "Iteration 41\n",
      "Iteration 42\n",
      "Iteration 43\n",
      "Iteration 44\n",
      "Iteration 45\n",
      "Iteration 46\n",
      "Iteration 47\n",
      "Iteration 48\n",
      "Iteration 49\n",
      "Iteration 50\n",
      "Iteration 51\n",
      "Iteration 52\n",
      "Iteration 53\n",
      "Iteration 54\n",
      "Iteration 55\n",
      "Iteration 56\n",
      "Iteration 57\n",
      "Iteration 58\n",
      "Iteration 59\n",
      "Iteration 60\n",
      "Iteration 61\n",
      "Iteration 62\n",
      "Iteration 63\n",
      "Iteration 64\n",
      "Iteration 65\n",
      "Iteration 66\n",
      "Iteration 67\n",
      "Iteration 68\n",
      "Iteration 69\n",
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n",
      "Iteration 30\n",
      "Iteration 31\n",
      "Iteration 32\n",
      "Iteration 33\n",
      "Iteration 34\n",
      "Iteration 35\n",
      "Iteration 36\n",
      "Iteration 37\n",
      "Iteration 38\n",
      "Iteration 39\n",
      "Iteration 40\n",
      "Iteration 41\n",
      "Iteration 42\n",
      "Iteration 43\n",
      "Iteration 44\n",
      "Iteration 45\n",
      "Iteration 46\n",
      "Iteration 47\n",
      "Iteration 48\n",
      "Iteration 49\n",
      "Iteration 50\n",
      "Iteration 51\n",
      "Iteration 52\n",
      "Iteration 53\n",
      "Iteration 54\n",
      "Iteration 55\n",
      "Iteration 56\n",
      "Iteration 57\n",
      "Iteration 58\n",
      "Iteration 59\n",
      "Iteration 60\n",
      "Iteration 61\n",
      "Iteration 62\n",
      "Iteration 63\n",
      "Iteration 64\n",
      "Iteration 65\n",
      "Iteration 66\n",
      "Iteration 67\n",
      "Iteration 68\n",
      "Iteration 69\n",
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n",
      "Iteration 30\n",
      "Iteration 31\n",
      "Iteration 32\n",
      "Iteration 33\n",
      "Iteration 34\n",
      "Iteration 35\n",
      "Iteration 36\n",
      "Iteration 37\n",
      "Iteration 38\n",
      "Iteration 39\n",
      "Iteration 40\n",
      "Iteration 41\n",
      "Iteration 42\n",
      "Iteration 43\n",
      "Iteration 44\n",
      "Iteration 45\n",
      "Iteration 46\n",
      "Iteration 47\n",
      "Iteration 48\n",
      "Iteration 49\n",
      "Iteration 50\n",
      "Iteration 51\n",
      "Iteration 52\n",
      "Iteration 53\n",
      "Iteration 54\n",
      "Iteration 55\n",
      "Iteration 56\n",
      "Iteration 57\n",
      "Iteration 58\n",
      "Iteration 59\n",
      "Iteration 60\n",
      "Iteration 61\n",
      "Iteration 62\n",
      "Iteration 63\n",
      "Iteration 64\n",
      "Iteration 65\n",
      "Iteration 66\n",
      "Iteration 67\n",
      "Iteration 68\n",
      "Iteration 69\n",
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n",
      "Iteration 8\n",
      "Iteration 9\n",
      "Iteration 10\n",
      "Iteration 11\n",
      "Iteration 12\n",
      "Iteration 13\n",
      "Iteration 14\n",
      "Iteration 15\n",
      "Iteration 16\n",
      "Iteration 17\n",
      "Iteration 18\n",
      "Iteration 19\n",
      "Iteration 20\n",
      "Iteration 21\n",
      "Iteration 22\n",
      "Iteration 23\n",
      "Iteration 24\n",
      "Iteration 25\n",
      "Iteration 26\n",
      "Iteration 27\n",
      "Iteration 28\n",
      "Iteration 29\n",
      "Iteration 30\n",
      "Iteration 31\n",
      "Iteration 32\n",
      "Iteration 33\n",
      "Iteration 34\n",
      "Iteration 35\n",
      "Iteration 36\n",
      "Iteration 37\n",
      "Iteration 38\n",
      "Iteration 39\n",
      "Iteration 40\n",
      "Iteration 41\n",
      "Iteration 42\n",
      "Iteration 43\n",
      "Iteration 44\n",
      "Iteration 45\n",
      "Iteration 46\n",
      "Iteration 47\n",
      "Iteration 48\n",
      "Iteration 49\n",
      "Iteration 50\n",
      "Iteration 51\n",
      "Iteration 52\n",
      "Iteration 53\n",
      "Iteration 54\n",
      "Iteration 55\n",
      "Iteration 56\n",
      "Iteration 57\n",
      "Iteration 58\n",
      "Iteration 59\n",
      "Iteration 60\n",
      "Iteration 61\n",
      "Iteration 62\n",
      "Iteration 63\n",
      "Iteration 64\n",
      "Iteration 65\n",
      "Iteration 66\n",
      "Iteration 67\n",
      "Iteration 68\n",
      "Iteration 69\n",
      "[1.0576631480122576, 1.0565792625994748, 1.0502885027573972, 1.0601641205486443]\n",
      "[0.9085895701988329, 0.9293554722260796, 0.9676895799808984, 1.1126091574632884]\n",
      "[0.5972569352692199, 0.5803324654825356, 0.59159969070618, 0.62449020826547]\n"
     ]
    }
   ],
   "source": [
    "df_ = df.copy(deep=True)\n",
    "D = np.asmatrix(df_)\n",
    "tmp_arr = copy.deepcopy(main_arr)\n",
    "frac_anomaly = round(100*150*0.1)//2\n",
    "#frac_anomaly = 0\n",
    "\n",
    "new_loss_result_list = []\n",
    "new_loss_result_list_2 = []\n",
    "new_loss_result_list_3 = []\n",
    "\n",
    "p_ = [0.2, 0.4, 0.8]\n",
    "anomaly_size = [0.5, 1, 2, 5]\n",
    "anomaly_ratio = [0, 0.05, 0.1, 0.2]\n",
    "loss_probability = [0.2, 0.4, 0.8]\n",
    "loss = 0.2\n",
    "anomaly_r = 0.1\n",
    "anomaly_s = 1\n",
    "\n",
    "#for p in p_:\n",
    "for anomaly_r in anomaly_ratio:\n",
    "#for anomaly_s in anomaly_size:\n",
    "#for loss in loss_probability:\n",
    "    new_nmae_err_list = []\n",
    "    new_nmae_err_list_2 = []\n",
    "    new_nmae_err_list_3 = []\n",
    "    nmae_err_list = []\n",
    "    nmae_err_list_2 = []\n",
    "    nmae_err_list_3 = []\n",
    "    frac_missing = round(100*150*loss)\n",
    "    frac_anomaly = anomaly_r\n",
    "    for i in range(1):\n",
    "#         #first technique\n",
    "        random_indx_y10_miss = np.random.randint(0, 100, size=round(100*150*loss))\n",
    "        random_indx_x10_miss = np.random.randint(0, 150, size=round(100*150*loss))\n",
    "        \n",
    "        #second technique\n",
    "        # random_indx_y10_miss = np.random.randint(0, 100, size=round(100*150*0.5))\n",
    "        # random_indx_x10_miss = np.random.randint(0, 150, size=round(100*150*p))\n",
    "        \n",
    "#         #third technique\n",
    "        # random_indx_y10_miss = np.random.randint(0, 100, size=round(100*150*p))\n",
    "        # random_indx_x10_miss = np.random.randint(0, 150, size=round(100*150*0.5))\n",
    "\n",
    "#         #fourth technique\n",
    "#         random_indx_y10_miss = np.array([i for i in range(100)])\n",
    "#         random_indx_x10_miss = np.random.randint(0, 150, size=round(100*150*loss))\n",
    "        \n",
    "#         #fifth technique\n",
    "        # random_indx_y10_miss = np.random.randint(0, 100, size=round(100*150*loss))\n",
    "        # random_indx_x10_miss = np.array([i for i in range(150)])\n",
    "      \n",
    "        list_D = []\n",
    "        list_result_D = []\n",
    "        list_result_D_2 = []\n",
    "        list_result_D_3 = []\n",
    "\n",
    "        tmp_arr = copy.deepcopy(main_arr)\n",
    "        for i in range(len(random_indx_x10_miss)):\n",
    "            x = int(random_indx_x10_miss[i])\n",
    "            y = int(random_indx_y10_miss[i])\n",
    "            list_D.append(main_arr[y][x])\n",
    "            tmp_arr[y][x] = None\n",
    "        \n",
    "        mean = np.nanmean(tmp_arr)\n",
    "        tmp_arr_for_svd = copy.deepcopy(tmp_arr)\n",
    "        tmp_arr_for_svd[np.isnan(tmp_arr_for_svd)] = 0\n",
    "        \n",
    "        indices = np.nonzero(np.isnan(tmp_arr_for_svd))  \n",
    "        random_indx_y10_anomal = np.random.randint(0, 100, size=round(100*150*anomaly_r))\n",
    "        random_indx_x10_anomal = np.random.randint(0, 150, size=round(100*150*anomaly_r))\n",
    "    \n",
    "        for i in range(len(random_indx_y10_anomal)):\n",
    "            y = int(random_indx_y10_anomal[i])\n",
    "            x = int(random_indx_x10_anomal[i])\n",
    "            tmp_arr[y][x] += s_1*anomaly_s\n",
    "            tmp_arr_for_svd[y][x] += s_1*anomaly_s\n",
    "        \n",
    "        U, sigma, V = np.linalg.svd(tmp_arr_for_svd)\n",
    "        # Выберем только первые две компоненты для аппроксимации\n",
    "        U = U[:, :2]\n",
    "        sigma = np.diag(sigma[:2])\n",
    "        V = V[:2, :]\n",
    "        # Вычислим аппроксимированную матрицу\n",
    "        D_approx = U @ sigma @ V\n",
    "        #print(D_approx)\n",
    "\n",
    "        # Применяем K ближайших соседей для локальной интерполяции:\n",
    "        knn = KNeighborsRegressor(n_neighbors=2)\n",
    "        matrix_interp = knn.fit(D_approx, main_arr).predict(D_approx)\n",
    "\n",
    "        # Получаем итоговую матрицу, заменяя пропущенные значения после локальной интерполяции:\n",
    "        D_svd_knn = copy.deepcopy(tmp_arr)\n",
    "        D_svd_knn[np.isnan(D_svd_knn)] = matrix_interp[np.isnan(D_svd_knn)]\n",
    "        for i in range(len(random_indx_x10_miss)):\n",
    "            x = int(random_indx_x10_miss[i])\n",
    "            y = int(random_indx_y10_miss[i])\n",
    "            list_result_D_3.append(D_svd_knn[y][x])\n",
    "            list_result_D_2.append(D_approx[y][x])\n",
    "            \n",
    "        m=100\n",
    "        n=150\n",
    "        result_D = ADMM(tmp_arr, frac_anomaly, frac_missing, random_indx_y10_miss, random_indx_x10_miss, m, n)\n",
    "        for i in range(len(random_indx_x10_miss)):\n",
    "            x = int(random_indx_x10_miss[i])\n",
    "            y = int(random_indx_y10_miss[i])\n",
    "            list_result_D.append(result_D[y][x])       \n",
    "        \n",
    "        raznost = [x - y for x, y in zip(list_D, list_result_D)]\n",
    "        raznost_2 = [x - y for x, y in zip(list_D, list_result_D_2)]\n",
    "        raznost_3 = [x - y for x, y in zip(list_D, list_result_D_3)]\n",
    "        new_nmae_err_list.append(np.mean(np.abs(raznost) / np.nanmean(np.abs(list_D))))\n",
    "        new_nmae_err_list_2.append(np.mean(np.abs(raznost_2) / np.nanmean(np.abs(list_D))))\n",
    "        new_nmae_err_list_3.append(np.mean(np.abs(raznost_3) / np.nanmean(np.abs(list_D))))\n",
    "    \n",
    "    new_loss_result_list.append(np.mean(new_nmae_err_list))\n",
    "    new_loss_result_list_2.append(np.mean(new_nmae_err_list_2))\n",
    "    new_loss_result_list_3.append(np.mean(new_nmae_err_list_3))   \n",
    "\n",
    "print(new_loss_result_list)\n",
    "print(new_loss_result_list_2)\n",
    "print(new_loss_result_list_3)        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Basic Python Environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
